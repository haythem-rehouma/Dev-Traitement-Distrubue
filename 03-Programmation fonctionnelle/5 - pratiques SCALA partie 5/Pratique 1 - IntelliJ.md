### **Tutoriel : Ex√©cution d‚Äôun Programme Spark en Scala avec Maven et IntelliJ IDEA**

**Objectif** : 

- Apprendre √† configurer un projet Scala avec Maven dans IntelliJ IDEA et ex√©cuter un programme Spark.

---

# **1. Pr√©requis**
Avant de commencer, assurez-vous d'avoir install√© :
- **Apache Spark 3.3.0**  
- **Java 8 (JDK 1.8)** (pour compatibilit√© avec Spark)  
- **Scala 2.12.7** (correspond √† votre version de Spark)  
- **Maven 3.9.0** (version pr√©cis√©e)  
- **IntelliJ IDEA avec le plugin Scala**  

---

# **üìÇ 2. Cr√©ation du Projet Maven dans IntelliJ IDEA**
### **1Ô∏è‚É£ Cr√©er un projet Maven**
1. **Ouvrez IntelliJ IDEA** et s√©lectionnez **"New Project"**.
2. Dans **"Project SDK"**, choisissez **JDK 1.8**.
3. S√©lectionnez **"Maven"** comme type de projet.
4. **D√©cochez** "Create from Archetype".
5. Cliquez sur **Next**, donnez un **nom au projet** et cliquez sur **Finish**.

---

### **2Ô∏è‚É£ Configuration du fichier `pom.xml`**
Dans IntelliJ IDEA, ouvrez le fichier **`pom.xml`** et **remplacez son contenu** par ce code :

```xml
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
  <modelVersion>4.0.0</modelVersion>
  <groupId>sample</groupId>
  <artifactId>scala-module-dependency-sample</artifactId>
  <version>1.0-SNAPSHOT</version>
  <properties>
    <encoding>UTF-8</encoding>
  </properties>
  <!-- Maven profiles allow you to support both Scala 2.10, 2.11 and Scala 2.12 with
    the right dependencies for modules specified for each version separately -->
  <profiles>
    <profile>
      <id>scala-2.12</id>
      <activation>
        <activeByDefault>true</activeByDefault>
      </activation>
      <properties>
        <scala.version>2.12.7</scala.version>
        <scala.compat.version>2.12</scala.compat.version>
      </properties>
      <dependencies>
        <dependency>
          <groupId>org.scala-lang</groupId>
          <artifactId>scala-library</artifactId>
          <version>${scala.version}</version>
        </dependency>
        <dependency>
          <groupId>org.scala-lang.modules</groupId>
          <artifactId>scala-xml_${scala.compat.version}</artifactId>
          <version>1.1.1</version>
        </dependency>
        <dependency>
          <groupId>org.scala-lang.modules</groupId>
          <artifactId>scala-parser-combinators_${scala.compat.version}</artifactId>
          <version>1.1.1</version>
        </dependency>
        <dependency>
          <groupId>org.scala-lang.modules</groupId>
          <artifactId>scala-swing_${scala.compat.version}</artifactId>
          <version>2.0.3</version>
        </dependency>




        <dependency>
          <groupId>org.apache.spark</groupId>
          <artifactId>spark-core_2.12</artifactId>
          <version>3.3.0</version> <!-- V√©rifiez la compatibilit√© avec votre version de Scala -->
        </dependency>

        <dependency>
          <groupId>org.apache.spark</groupId>
          <artifactId>spark-sql_2.12</artifactId>
          <version>3.3.0</version>
        </dependency>


      </dependencies>
    </profile>
    <profile>
      <id>scala-2.11</id>
      <properties>
        <scala.version>2.11.12</scala.version>
        <scala.compat.version>2.11</scala.compat.version>
      </properties>
      <dependencies>
        <dependency>
          <groupId>org.scala-lang</groupId>
          <artifactId>scala-library</artifactId>
          <version>${scala.version}</version>
        </dependency>
        <dependency>
          <groupId>org.scala-lang.modules</groupId>
          <artifactId>scala-xml_${scala.compat.version}</artifactId>
          <version>1.1.1</version>
        </dependency>
        <dependency>
          <groupId>org.scala-lang.modules</groupId>
          <artifactId>scala-parser-combinators_${scala.compat.version}</artifactId>
          <version>1.1.1</version>
        </dependency>

      </dependencies>
    </profile>
    <profile>
      <id>scala-2.10</id>
      <properties>
        <scala.version>2.10.7</scala.version>
        <scala.compat.version>2.10</scala.compat.version>
      </properties>
      <dependencies>
        <dependency>
          <groupId>org.scala-lang</groupId>
          <artifactId>scala-library</artifactId>
          <version>${scala.version}</version>
        </dependency>

      </dependencies>
    </profile>
  </profiles>
  <build>
    <sourceDirectory>src/main/scala</sourceDirectory>
    <testSourceDirectory>src/test/scala</testSourceDirectory>
    <plugins>
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-compiler-plugin</artifactId>
        <version>3.3</version>
      </plugin>
      <plugin>
        <groupId>net.alchim31.maven</groupId>
        <artifactId>scala-maven-plugin</artifactId>
        <version>3.2.2</version>
        <executions>
          <execution>
            <goals>
              <goal>compile</goal>
              <goal>testCompile</goal>
            </goals>
          </execution>
        </executions>
        <configuration>
          <args>
            <!-- work-around for https://issues.scala-lang.org/browse/SI-8358 -->
            <arg>-nobootcp</arg>
          </args>
        </configuration>
      </plugin>
    </plugins>
  </build>
</project>
```

---

### **3Ô∏è‚É£ Recharger le projet Maven**
1. **Cliquez sur l‚Äôonglet "Maven"** dans IntelliJ IDEA.
2. Cliquez sur **"Reload All Maven Projects"** (ic√¥ne de rafra√Æchissement).
3. Attendez que Maven t√©l√©charge toutes les d√©pendances.

---

# **3. Ajout du Code Scala**
Dans le dossier `src/main/scala`, cr√©ez un fichier `StockProcessor.scala` et **collez le code suivant** :

```scala
// Importation des biblioth√®ques n√©cessaires

import org.apache.spark.sql.{SparkSession, DataFrame}  // DataFrame est ici correctement import√©
import org.apache.spark.rdd.RDD
import org.apache.spark.sql.Encoders


// D√©finition de la case class pour les stocks
case class Stock(
                  dt: String,
                  openprice: Double,
                  highprice: Double,
                  lowprice: Double,
                  closeprice: Double,
                  volume: Double,
                  adjcloseprice: Double
                )

// Objet contenant les m√©thodes pour parser et charger les donn√©es
object StockProcessor {

  def parseStock(str: String): Option[Stock] = {
    val line = str.split(",")

    try {
      Some(Stock(
        line(0),
        line(1).toDouble,
        line(2).toDouble,
        line(3).toDouble,
        line(4).toDouble,
        line(5).toDouble,
        line(6).toDouble
      ))
    } catch {
      case e: Exception =>
        println(s"Erreur de parsing pour la ligne : $str -> ${e.getMessage}")
        None
    }
  }
  def parseRDD(rdd: RDD[String]): RDD[Stock] = {
    val header = rdd.first() // R√©cup√©ration de l'en-t√™te
    rdd
      .filter(_ != header) // Suppression de l'en-t√™te
      .flatMap(parseStock) // Utilisation de flatMap pour ignorer les erreurs
      .cache()
  }
  def main(args: Array[String]): Unit = {
    // Cr√©ation de la session Spark
    val spark = SparkSession.builder()
      .appName("Stock Analysis")
      .master("local[*]") // Mode local
      .getOrCreate()

    import spark.implicits._ // Import pour convertir RDD en DataFrame

    // Charger le fichier CSV et transformer en DataFrame
    val stocksAAPLDF: DataFrame = parseRDD(spark.sparkContext.textFile("C:/Users/rehou/Downloads/AAPL.csv"))
      .toDF() // Conversion en DataFrame
      .cache()

    // Affichage des premi√®res lignes
    stocksAAPLDF.show()
  }
}
```

---

# **‚öô 4. Configuration de l‚ÄôEx√©cution**
### **üîπ Modifier les Configurations d'Ex√©cution**
1. **Cliquez sur le bouton vert ‚ñ∂** en haut.
2. S√©lectionnez **"Edit Configurations..."**.
3. Cliquez sur **"Modify options"**.
4. Cochez **"Allow multiple instances"**.
5. Allez dans *Build and run.* ¬≠> *Select Alternative JRE*
6. **S√©lectionnez Java 8** dans les param√®tres d‚Äôex√©cution.
7. Cliquez sur **Run**

---

# **‚ñ∂ 5. Ex√©cuter le Programme**
1. Cliquez sur **le bouton vert ‚ñ∂** √† c√¥t√© de `main()`.
2. Attendez que Spark d√©marre et affiche les r√©sultats.

---

# **6. R√©sultat Attendu**
```
+----------+---------+---------+---------+---------+-------+-------------+
|       dt |openprice|highprice|lowprice |closeprice|volume|adjcloseprice|
+----------+---------+---------+---------+---------+-------+-------------+
|2023-01-02|  125.02 |  130.05 |  124.52 |  129.43 |200000 |  129.43     |
|2023-01-03|  129.55 |  132.00 |  127.75 |  130.98 |220000 |  130.98     |
|2023-01-04|  131.00 |  135.12 |  130.45 |  134.52 |250000 |  134.52     |
+----------+---------+---------+---------+---------+-------+-------------+
```

---

# **7. Exercice**
1. **Changer le chemin du fichier CSV** en fonction de votre syst√®me.
2. **Ajouter une colonne `prix_moyen`** (`(openprice + closeprice) / 2`).
3. **Appliquer un filtre** pour afficher uniquement les actions avec un `volume > 210000`.



# 8. Annexe 1 - Remarques Importantes 

1Ô∏è‚É£ **Version de Maven** :  
   - **Il est imp√©ratif d‚Äôutiliser Maven 3.9.0**.  
   - **Si vous utilisez une autre version, vous risquez d‚Äôavoir des erreurs de compilation**.  
   - Vous pouvez v√©rifier votre version avec la commande suivante dans le terminal :  
     ```sh
     mvn -version
     ```
   - Si ce n‚Äôest pas la bonne version, mettez √† jour Maven ou t√©l√©chargez **Maven 3.9.0** depuis [Apache Maven](https://maven.apache.org/download.cgi).

---

2Ô∏è‚É£ **Version de Java** :  
   - **Seule la version Java 8 (JDK 1.8) est compatible avec Spark 3.3.0 et Scala 2.12.7.**  
   - **N‚Äôutilisez pas Java 11, 17 ou plus, cela entra√Ænera des erreurs de compatibilit√©**.  
   - V√©rifiez votre version de Java avec la commande :  
     ```sh
     java -version
     ```
   - Si ce n‚Äôest pas Java 8, vous devez l‚Äôinstaller et le d√©finir comme version active.

---

3Ô∏è‚É£ **Configuration d'IntelliJ IDEA** :  
   - **Dans les param√®tres d'ex√©cution du projet, il est obligatoire d‚Äôactiver "Allow multiple instances"**.  
   - Pour cela :  
     1. **Cliquez sur "Run/Debug Configurations"**.  
     2. **S√©lectionnez votre application Spark**.  
     3. **Cochez l‚Äôoption "Allow multiple instances"**.  



# Annexe 1 - arborescence de notre pom.xml

*Cette arborescence dans notre annexe permet de visualiser clairement la hi√©rarchie de votre fichier `pom.xml`, y compris les d√©pendances, les propri√©t√©s, les profils Maven et les plugins utilis√©s.*

```
project
‚îú‚îÄ‚îÄ modelVersion: 4.0.0
‚îú‚îÄ‚îÄ groupId: sample
‚îú‚îÄ‚îÄ artifactId: scala-module-dependency-sample
‚îú‚îÄ‚îÄ version: 1.0-SNAPSHOT
‚îú‚îÄ‚îÄ properties
‚îÇ   ‚îú‚îÄ‚îÄ encoding: UTF-8
‚îú‚îÄ‚îÄ profiles
‚îÇ   ‚îú‚îÄ‚îÄ profile (id: scala-2.12)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ activation
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ activeByDefault: true
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ properties
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scala.version: 2.12.7
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scala.compat.version: 2.12
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dependencies
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dependency (org.scala-lang:scala-library:${scala.version})
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dependency (org.scala-lang.modules:scala-xml_${scala.compat.version}:1.1.1)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dependency (org.scala-lang.modules:scala-parser-combinators_${scala.compat.version}:1.1.1)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dependency (org.scala-lang.modules:scala-swing_${scala.compat.version}:2.0.3)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dependency (org.apache.spark:spark-core_2.12:3.3.0)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dependency (org.apache.spark:spark-sql_2.12:3.3.0)
‚îÇ   ‚îú‚îÄ‚îÄ profile (id: scala-2.11)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ properties
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scala.version: 2.11.12
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scala.compat.version: 2.11
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dependencies
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dependency (org.scala-lang:scala-library:${scala.version})
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dependency (org.scala-lang.modules:scala-xml_${scala.compat.version}:1.1.1)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dependency (org.scala-lang.modules:scala-parser-combinators_${scala.compat.version}:1.1.1)
‚îÇ   ‚îú‚îÄ‚îÄ profile (id: scala-2.10)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ properties
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scala.version: 2.10.7
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scala.compat.version: 2.10
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dependencies
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dependency (org.scala-lang:scala-library:${scala.version})
‚îú‚îÄ‚îÄ build
‚îÇ   ‚îú‚îÄ‚îÄ sourceDirectory: src/main/scala
‚îÇ   ‚îú‚îÄ‚îÄ testSourceDirectory: src/test/scala
‚îÇ   ‚îú‚îÄ‚îÄ plugins
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ plugin (org.apache.maven.plugins:maven-compiler-plugin:3.3)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ plugin (net.alchim31.maven:scala-maven-plugin:3.2.2)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ executions
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ execution
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ goals
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ goal: compile
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ goal: testCompile
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ configuration
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ args
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ arg: -nobootcp
```


