### **Tutoriel : ExÃ©cution dâ€™un Programme Spark en Scala avec Maven et IntelliJ IDEA**

**Objectif** : 

- Apprendre Ã  configurer un projet Scala avec Maven dans IntelliJ IDEA et exÃ©cuter un programme Spark.

---

# **1. PrÃ©requis**
Avant de commencer, assurez-vous d'avoir installÃ© :
- **Apache Spark 3.3.0**  
- **Java 8 (JDK 1.8)** (pour compatibilitÃ© avec Spark)  
- **Scala 2.12.7** (correspond Ã  votre version de Spark)  
- **Maven 3.9.0** (version prÃ©cisÃ©e)  
- **IntelliJ IDEA avec le plugin Scala**  

---

# **ğŸ“‚ 2. CrÃ©ation du Projet Maven dans IntelliJ IDEA**
### **1ï¸âƒ£ CrÃ©er un projet Maven**
1. **Ouvrez IntelliJ IDEA** et sÃ©lectionnez **"New Project"**.
2. Dans **"Project SDK"**, choisissez **JDK 1.8**.
3. SÃ©lectionnez **"Maven"** comme type de projet.
4. **DÃ©cochez** "Create from Archetype".
5. Cliquez sur **Next**, donnez un **nom au projet** et cliquez sur **Finish**.

---

### **2ï¸âƒ£ Configuration du fichier `pom.xml`**
Dans IntelliJ IDEA, ouvrez le fichier **`pom.xml`** et **remplacez son contenu** par ce code :

```xml
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
  <modelVersion>4.0.0</modelVersion>
  <groupId>sample</groupId>
  <artifactId>scala-module-dependency-sample</artifactId>
  <version>1.0-SNAPSHOT</version>
  <properties>
    <encoding>UTF-8</encoding>
  </properties>
  <!-- Maven profiles allow you to support both Scala 2.10, 2.11 and Scala 2.12 with
    the right dependencies for modules specified for each version separately -->
  <profiles>
    <profile>
      <id>scala-2.12</id>
      <activation>
        <activeByDefault>true</activeByDefault>
      </activation>
      <properties>
        <scala.version>2.12.7</scala.version>
        <scala.compat.version>2.12</scala.compat.version>
      </properties>
      <dependencies>
        <dependency>
          <groupId>org.scala-lang</groupId>
          <artifactId>scala-library</artifactId>
          <version>${scala.version}</version>
        </dependency>
        <dependency>
          <groupId>org.scala-lang.modules</groupId>
          <artifactId>scala-xml_${scala.compat.version}</artifactId>
          <version>1.1.1</version>
        </dependency>
        <dependency>
          <groupId>org.scala-lang.modules</groupId>
          <artifactId>scala-parser-combinators_${scala.compat.version}</artifactId>
          <version>1.1.1</version>
        </dependency>
        <dependency>
          <groupId>org.scala-lang.modules</groupId>
          <artifactId>scala-swing_${scala.compat.version}</artifactId>
          <version>2.0.3</version>
        </dependency>




        <dependency>
          <groupId>org.apache.spark</groupId>
          <artifactId>spark-core_2.12</artifactId>
          <version>3.3.0</version> <!-- VÃ©rifiez la compatibilitÃ© avec votre version de Scala -->
        </dependency>

        <dependency>
          <groupId>org.apache.spark</groupId>
          <artifactId>spark-sql_2.12</artifactId>
          <version>3.3.0</version>
        </dependency>


      </dependencies>
    </profile>
    <profile>
      <id>scala-2.11</id>
      <properties>
        <scala.version>2.11.12</scala.version>
        <scala.compat.version>2.11</scala.compat.version>
      </properties>
      <dependencies>
        <dependency>
          <groupId>org.scala-lang</groupId>
          <artifactId>scala-library</artifactId>
          <version>${scala.version}</version>
        </dependency>
        <dependency>
          <groupId>org.scala-lang.modules</groupId>
          <artifactId>scala-xml_${scala.compat.version}</artifactId>
          <version>1.1.1</version>
        </dependency>
        <dependency>
          <groupId>org.scala-lang.modules</groupId>
          <artifactId>scala-parser-combinators_${scala.compat.version}</artifactId>
          <version>1.1.1</version>
        </dependency>

      </dependencies>
    </profile>
    <profile>
      <id>scala-2.10</id>
      <properties>
        <scala.version>2.10.7</scala.version>
        <scala.compat.version>2.10</scala.compat.version>
      </properties>
      <dependencies>
        <dependency>
          <groupId>org.scala-lang</groupId>
          <artifactId>scala-library</artifactId>
          <version>${scala.version}</version>
        </dependency>

      </dependencies>
    </profile>
  </profiles>
  <build>
    <sourceDirectory>src/main/scala</sourceDirectory>
    <testSourceDirectory>src/test/scala</testSourceDirectory>
    <plugins>
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-compiler-plugin</artifactId>
        <version>3.3</version>
      </plugin>
      <plugin>
        <groupId>net.alchim31.maven</groupId>
        <artifactId>scala-maven-plugin</artifactId>
        <version>3.2.2</version>
        <executions>
          <execution>
            <goals>
              <goal>compile</goal>
              <goal>testCompile</goal>
            </goals>
          </execution>
        </executions>
        <configuration>
          <args>
            <!-- work-around for https://issues.scala-lang.org/browse/SI-8358 -->
            <arg>-nobootcp</arg>
          </args>
        </configuration>
      </plugin>
    </plugins>
  </build>
</project>
```

---

### **3ï¸âƒ£ Recharger le projet Maven**
1. **Cliquez sur lâ€™onglet "Maven"** dans IntelliJ IDEA.
2. Cliquez sur **"Reload All Maven Projects"** (icÃ´ne de rafraÃ®chissement).
3. Attendez que Maven tÃ©lÃ©charge toutes les dÃ©pendances.

---

# **3. Ajout du Code Scala**
Dans le dossier `src/main/scala`, crÃ©ez un fichier `StockProcessor.scala` et **collez le code suivant** :

```scala
// Importation des bibliothÃ¨ques nÃ©cessaires

import org.apache.spark.sql.{SparkSession, DataFrame}  // DataFrame est ici correctement importÃ©
import org.apache.spark.rdd.RDD
import org.apache.spark.sql.Encoders


// DÃ©finition de la case class pour les stocks
case class Stock(
                  dt: String,
                  openprice: Double,
                  highprice: Double,
                  lowprice: Double,
                  closeprice: Double,
                  volume: Double,
                  adjcloseprice: Double
                )

// Objet contenant les mÃ©thodes pour parser et charger les donnÃ©es
object StockProcessor {

  def parseStock(str: String): Option[Stock] = {
    val line = str.split(",")

    try {
      Some(Stock(
        line(0),
        line(1).toDouble,
        line(2).toDouble,
        line(3).toDouble,
        line(4).toDouble,
        line(5).toDouble,
        line(6).toDouble
      ))
    } catch {
      case e: Exception =>
        println(s"Erreur de parsing pour la ligne : $str -> ${e.getMessage}")
        None
    }
  }
  def parseRDD(rdd: RDD[String]): RDD[Stock] = {
    val header = rdd.first() // RÃ©cupÃ©ration de l'en-tÃªte
    rdd
      .filter(_ != header) // Suppression de l'en-tÃªte
      .flatMap(parseStock) // Utilisation de flatMap pour ignorer les erreurs
      .cache()
  }
  def main(args: Array[String]): Unit = {
    // CrÃ©ation de la session Spark
    val spark = SparkSession.builder()
      .appName("Stock Analysis")
      .master("local[*]") // Mode local
      .getOrCreate()

    import spark.implicits._ // Import pour convertir RDD en DataFrame

    // Charger le fichier CSV et transformer en DataFrame
    val stocksAAPLDF: DataFrame = parseRDD(spark.sparkContext.textFile("C:/Users/rehou/Downloads/AAPL.csv"))
      .toDF() // Conversion en DataFrame
      .cache()

    // Affichage des premiÃ¨res lignes
    stocksAAPLDF.show()
  }
}
```

---

# **âš™ 4. Configuration de lâ€™ExÃ©cution**
### **ğŸ”¹ Modifier les Configurations d'ExÃ©cution**
1. **Cliquez sur le bouton vert â–¶** en haut.
2. SÃ©lectionnez **"Edit Configurations..."**.
3. Cliquez sur **"Modify options"**.
4. Cochez **"Allow multiple instances"**.
5. Allez dans *Build and run.* Â­> *Select Alternative JRE*
6. **SÃ©lectionnez Java 8** dans les paramÃ¨tres dâ€™exÃ©cution.
7. Cliquez sur **Run**

---

# **â–¶ 5. ExÃ©cuter le Programme**
1. Cliquez sur **le bouton vert â–¶** Ã  cÃ´tÃ© de `main()`.
2. Attendez que Spark dÃ©marre et affiche les rÃ©sultats.

---

# **6. RÃ©sultat Attendu**
```
+----------+---------+---------+---------+---------+-------+-------------+
|       dt |openprice|highprice|lowprice |closeprice|volume|adjcloseprice|
+----------+---------+---------+---------+---------+-------+-------------+
|2023-01-02|  125.02 |  130.05 |  124.52 |  129.43 |200000 |  129.43     |
|2023-01-03|  129.55 |  132.00 |  127.75 |  130.98 |220000 |  130.98     |
|2023-01-04|  131.00 |  135.12 |  130.45 |  134.52 |250000 |  134.52     |
+----------+---------+---------+---------+---------+-------+-------------+
```

---

# **7. Exercice**
1. **Changer le chemin du fichier CSV** en fonction de votre systÃ¨me.
2. **Ajouter une colonne `prix_moyen`** (`(openprice + closeprice) / 2`).
3. **Appliquer un filtre** pour afficher uniquement les actions avec un `volume > 210000`.



# 8. Annexe 1 - Remarques Importantes 

1ï¸âƒ£ **Version de Maven** :  
   - **Il est impÃ©ratif dâ€™utiliser Maven 3.9.0**.  
   - **Si vous utilisez une autre version, vous risquez dâ€™avoir des erreurs de compilation**.  
   - Vous pouvez vÃ©rifier votre version avec la commande suivante dans le terminal :  
     ```sh
     mvn -version
     ```
   - Si ce nâ€™est pas la bonne version, mettez Ã  jour Maven ou tÃ©lÃ©chargez **Maven 3.9.0** depuis [Apache Maven](https://maven.apache.org/download.cgi).

---

2ï¸âƒ£ **Version de Java** :  
   - **Seule la version Java 8 (JDK 1.8) est compatible avec Spark 3.3.0 et Scala 2.12.7.**  
   - **Nâ€™utilisez pas Java 11, 17 ou plus, cela entraÃ®nera des erreurs de compatibilitÃ©**.  
   - VÃ©rifiez votre version de Java avec la commande :  
     ```sh
     java -version
     ```
   - Si ce nâ€™est pas Java 8, vous devez lâ€™installer et le dÃ©finir comme version active.

---

3ï¸âƒ£ **Configuration d'IntelliJ IDEA** :  
   - **Dans les paramÃ¨tres d'exÃ©cution du projet, il est obligatoire dâ€™activer "Allow multiple instances"**.  
   - Pour cela :  
     1. **Cliquez sur "Run/Debug Configurations"**.  
     2. **SÃ©lectionnez votre application Spark**.  
     3. **Cochez lâ€™option "Allow multiple instances"**.  



# Annexe 1 - arborescence de notre pom.xml

*Cette arborescence dans notre annexe permet de visualiser clairement la hiÃ©rarchie de votre fichier `pom.xml`, y compris les dÃ©pendances, les propriÃ©tÃ©s, les profils Maven et les plugins utilisÃ©s.*

```
project
â”œâ”€â”€ modelVersion: 4.0.0
â”œâ”€â”€ groupId: sample
â”œâ”€â”€ artifactId: scala-module-dependency-sample
â”œâ”€â”€ version: 1.0-SNAPSHOT
â”œâ”€â”€ properties
â”‚   â”œâ”€â”€ encoding: UTF-8
â”œâ”€â”€ profiles
â”‚   â”œâ”€â”€ profile (id: scala-2.12)
â”‚   â”‚   â”œâ”€â”€ activation
â”‚   â”‚   â”‚   â”œâ”€â”€ activeByDefault: true
â”‚   â”‚   â”œâ”€â”€ properties
â”‚   â”‚   â”‚   â”œâ”€â”€ scala.version: 2.12.7
â”‚   â”‚   â”‚   â”œâ”€â”€ scala.compat.version: 2.12
â”‚   â”‚   â”œâ”€â”€ dependencies
â”‚   â”‚   â”‚   â”œâ”€â”€ dependency (org.scala-lang:scala-library:${scala.version})
â”‚   â”‚   â”‚   â”œâ”€â”€ dependency (org.scala-lang.modules:scala-xml_${scala.compat.version}:1.1.1)
â”‚   â”‚   â”‚   â”œâ”€â”€ dependency (org.scala-lang.modules:scala-parser-combinators_${scala.compat.version}:1.1.1)
â”‚   â”‚   â”‚   â”œâ”€â”€ dependency (org.scala-lang.modules:scala-swing_${scala.compat.version}:2.0.3)
â”‚   â”‚   â”‚   â”œâ”€â”€ dependency (org.apache.spark:spark-core_2.12:3.3.0)
â”‚   â”‚   â”‚   â”œâ”€â”€ dependency (org.apache.spark:spark-sql_2.12:3.3.0)
â”‚   â”œâ”€â”€ profile (id: scala-2.11)
â”‚   â”‚   â”œâ”€â”€ properties
â”‚   â”‚   â”‚   â”œâ”€â”€ scala.version: 2.11.12
â”‚   â”‚   â”‚   â”œâ”€â”€ scala.compat.version: 2.11
â”‚   â”‚   â”œâ”€â”€ dependencies
â”‚   â”‚   â”‚   â”œâ”€â”€ dependency (org.scala-lang:scala-library:${scala.version})
â”‚   â”‚   â”‚   â”œâ”€â”€ dependency (org.scala-lang.modules:scala-xml_${scala.compat.version}:1.1.1)
â”‚   â”‚   â”‚   â”œâ”€â”€ dependency (org.scala-lang.modules:scala-parser-combinators_${scala.compat.version}:1.1.1)
â”‚   â”œâ”€â”€ profile (id: scala-2.10)
â”‚   â”‚   â”œâ”€â”€ properties
â”‚   â”‚   â”‚   â”œâ”€â”€ scala.version: 2.10.7
â”‚   â”‚   â”‚   â”œâ”€â”€ scala.compat.version: 2.10
â”‚   â”‚   â”œâ”€â”€ dependencies
â”‚   â”‚   â”‚   â”œâ”€â”€ dependency (org.scala-lang:scala-library:${scala.version})
â”œâ”€â”€ build
â”‚   â”œâ”€â”€ sourceDirectory: src/main/scala
â”‚   â”œâ”€â”€ testSourceDirectory: src/test/scala
â”‚   â”œâ”€â”€ plugins
â”‚   â”‚   â”œâ”€â”€ plugin (org.apache.maven.plugins:maven-compiler-plugin:3.3)
â”‚   â”‚   â”œâ”€â”€ plugin (net.alchim31.maven:scala-maven-plugin:3.2.2)
â”‚   â”‚   â”‚   â”œâ”€â”€ executions
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ execution
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ goals
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ goal: compile
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ goal: testCompile
â”‚   â”‚   â”‚   â”œâ”€â”€ configuration
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ args
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ arg: -nobootcp
```

---
# Annexe 2 - Explication dÃ©taillÃ©e de chaque section de notre fichier `pom.xml`
---

*Avec cet annexe, **vous comprendrez comment fonctionne un `pom.xml`** pour un projet **Scala avec Spark et Maven dans IntelliJ IDEA** !*



### **ğŸ“Œ Explication des Sections du `pom.xml`**
```
+----------------------+----------------------------------------------------------+
|      Section        |                          Explication                       |
+----------------------+----------------------------------------------------------+
| project             | DÃ©crit le projet Maven et contient toutes les autres      |
|                      | sections nÃ©cessaires pour le build et la gestion des     |
|                      | dÃ©pendances.                                             |
+----------------------+----------------------------------------------------------+
| modelVersion        | Indique la version du modÃ¨le de projet Maven utilisÃ©.     |
|                      | Ici, c'est la version `4.0.0` qui est standard.          |
+----------------------+----------------------------------------------------------+
| groupId             | Identifie le groupe du projet. C'est une sorte de         |
|                      | "namespace". Ici, `sample` est dÃ©fini.                   |
+----------------------+----------------------------------------------------------+
| artifactId          | Nom unique du projet dans le groupe. Ici,                 |
|                      | `scala-module-dependency-sample` est dÃ©fini.             |
+----------------------+----------------------------------------------------------+
| version             | Version actuelle du projet. Ici, `1.0-SNAPSHOT` indique   |
|                      | quâ€™il sâ€™agit dâ€™une version en dÃ©veloppement.             |
+----------------------+----------------------------------------------------------+
| properties          | Contient des variables globales pour le projet Maven.     |
|                      | Exemple : `encoding=UTF-8` pour gÃ©rer lâ€™encodage.        |
+----------------------+----------------------------------------------------------+
| profiles            | Permet de dÃ©finir plusieurs configurations pour un mÃªme   |
|                      | projet. Chaque `profile` peut contenir des dÃ©pendances   |
|                      | diffÃ©rentes selon les besoins.                           |
+----------------------+----------------------------------------------------------+
| profile scala-2.12  | Configuration spÃ©cifique pour Scala 2.12.7.               |
|                      | Il dÃ©finit les dÃ©pendances pour cette version.           |
+----------------------+----------------------------------------------------------+
| profile scala-2.11  | Configuration spÃ©cifique pour Scala 2.11.12.              |
|                      | Il dÃ©finit ses propres dÃ©pendances.                      |
+----------------------+----------------------------------------------------------+
| profile scala-2.10  | Configuration spÃ©cifique pour Scala 2.10.7.               |
|                      | Il dÃ©finit ses propres dÃ©pendances.                      |
+----------------------+----------------------------------------------------------+
| dependencies        | Liste des bibliothÃ¨ques nÃ©cessaires pour exÃ©cuter le code.|
|                      | Exemple : Spark, Scala standard, XML, Parser, etc.      |
+----------------------+----------------------------------------------------------+
| build              | Contient les instructions pour compiler et exÃ©cuter le    |
|                      | projet. Il inclut des plugins qui facilitent le travail.|
+----------------------+----------------------------------------------------------+
| sourceDirectory     | DÃ©finit oÃ¹ se trouvent les fichiers Scala.                |
|                      | Ici, `src/main/scala` est dÃ©fini comme source.          |
+----------------------+----------------------------------------------------------+
| testSourceDirectory | DÃ©finit oÃ¹ se trouvent les fichiers de tests Scala.      |
|                      | Ici, `src/test/scala` est dÃ©fini.                        |
+----------------------+----------------------------------------------------------+
| plugins             | Liste des outils Maven qui aident au processus de build.  |
+----------------------+----------------------------------------------------------+
| maven-compiler-plugin | Plugin pour compiler le code Java/Scala dans le projet. |
|                      | Ici, la version utilisÃ©e est `3.3`.                      |
+----------------------+----------------------------------------------------------+
| scala-maven-plugin  | Plugin qui permet de compiler et exÃ©cuter du Scala       |
|                      | dans un projet Maven. Version `3.2.2` utilisÃ©e ici.      |
+----------------------+----------------------------------------------------------+
| executions         | DÃ©finit quelles tÃ¢ches Maven doit exÃ©cuter automatiquement.|
|                      | Exemple : compilation et test du code Scala.            |
+----------------------+----------------------------------------------------------+
| goals               | Liste des actions Ã  exÃ©cuter lors du build.               |
|                      | Ici : `compile` (compiler le code), `testCompile` (tests).|
+----------------------+----------------------------------------------------------+
| configuration       | Contient des paramÃ¨tres avancÃ©s pour les plugins.         |
|                      | Exemple : `-nobootcp` pour Ã©viter certains conflits.    |
+----------------------+----------------------------------------------------------+
```

---

### **ğŸ›  DÃ©tails des Versions Scala utilisÃ©es**
```
+------------+------------------------------+--------------------------+
| Version    | CompatibilitÃ© avec Spark     | Commentaire               |
+------------+------------------------------+--------------------------+
| Scala 2.12 | Compatible avec Spark 3.3.0  | UtilisÃ©e par dÃ©faut       |
+------------+------------------------------+--------------------------+
| Scala 2.11 | Ancienne version supportÃ©e   | NÃ©cessaire pour certains  |
|            | mais obsolÃ¨te pour Spark 3.x | projets legacy            |
+------------+------------------------------+--------------------------+
| Scala 2.10 | TrÃ¨s ancienne version        | Rarement utilisÃ©e         |
+------------+------------------------------+--------------------------+
```

---

### **ğŸš€ Explication des Profils (`profiles`)**
Les **profils Maven** permettent dâ€™avoir **diffÃ©rentes configurations** pour un mÃªme projet. Ici, trois profils sont dÃ©finis :
1. **Scala 2.12 (Par dÃ©faut)** :  
   - Active les dÃ©pendances pour Scala 2.12.7.  
   - Utilise Spark 3.3.0.  

2. **Scala 2.11** :  
   - Charge les dÃ©pendances pour Scala 2.11.12.  
   - Peut Ãªtre utile pour des projets plus anciens.  

3. **Scala 2.10** :  
   - DÃ©finit les bibliothÃ¨ques compatibles avec Scala 2.10.7.  
   - TrÃ¨s peu utilisÃ© aujourdâ€™hui.  

---

### **ğŸ“¦ Explication des DÃ©pendances (`dependencies`)**
```
+------------------------------------------+--------------------------------------------+
| DÃ©pendance                               | Explication                                |
+------------------------------------------+--------------------------------------------+
| org.scala-lang:scala-library             | BibliothÃ¨que standard Scala                |
|                                          | Permet d'exÃ©cuter du code Scala            |
+------------------------------------------+--------------------------------------------+
| org.scala-lang.modules:scala-xml         | Gestion des fichiers XML en Scala         |
+------------------------------------------+--------------------------------------------+
| org.scala-lang.modules:scala-parser-...  | Librairie pour parser du texte            |
+------------------------------------------+--------------------------------------------+
| org.apache.spark:spark-core_2.12         | Noyau de Spark pour Scala 2.12            |
+------------------------------------------+--------------------------------------------+
| org.apache.spark:spark-sql_2.12          | BibliothÃ¨que SQL de Spark                 |
+------------------------------------------+--------------------------------------------+
```

---

### **ğŸ›  Explication des Plugins (`plugins`)**
1. **maven-compiler-plugin**  
   - UtilisÃ© pour compiler le code Java et Scala.  
   - Version `3.3` utilisÃ©e ici.  

2. **scala-maven-plugin**  
   - Permet de compiler du **Scala** avec **Maven**.  
   - Version `3.2.2`.  
   - DÃ©finit que **`compile` et `testCompile`** doivent Ãªtre exÃ©cutÃ©s.  

---

### **ğŸ¯ ExÃ©cutions (`executions`)**
Lâ€™exÃ©cution dÃ©finit **quelles tÃ¢ches** Maven doit rÃ©aliser lors du build :
- **compile** : Compile le code Scala.  
- **testCompile** : Compile les tests Scala.  

---

### **âš™ Configuration**
Dans la section **configuration**, lâ€™argument `-nobootcp` est utilisÃ© pour Ã©viter certains conflits de classpath avec Scala.

---

### **ğŸ“Œ RÃ©capitulatif**
- **Le projet utilise trois versions de Scala (2.12, 2.11, 2.10)** mais **Scala 2.12 est activÃ© par dÃ©faut**.  
- **Les dÃ©pendances Spark et Scala sont chargÃ©es dynamiquement selon le profil sÃ©lectionnÃ©**.  
- **Les plugins permettent de compiler et exÃ©cuter du code Scala avec Maven**.  
- **Lâ€™exÃ©cution de Maven compile le code et les tests Scala**.  



